
---

# Task #1: Single-source Augmentation

This directory contains the full pipeline for Task 1, which covers data synthesis, data augmentation, and model training using a retrieval-augmented generation (RAG) approach.

## Solution Overview

My solution is based on a RAG (Retrieval-Augmented Generation) framework. The core idea is to retrieve the top-10 text passages most relevant to the input image, then use these passages, together with the question and the image itself, as input to the model.

### Pipeline Steps

1. **Image-based Text Retrieval**  
   For each image, I retrieve the top-10 most relevant text passages using an image-to-text search module. These passages are intended to provide additional context for answering the question.

2. **RAG-based Answer Generation**  
   I use Llama to generate answers, taking as input the question, the image, and the retrieved top-10 texts. The prompt is carefully designed to incorporate both the image and the retrieved information.

3. **Answer Verification and Filtering**  
   Each answer generated by Llama is then checked for correctness using GPT-4o. If the answer is accurate, it is kept; if not, it is replaced with "I do not know."

4. **Data Augmentation via GPT-4**  
   For each verified answer, I use GPT-4 to generate 20 additional variations. These variations are either more concise or more complex, but each is limited to 50 words. GPT-4o is then used to filter and label the correct ones, which are kept as augmented training samples.

5. **Model Fine-tuning**  
   I fine-tune Llama with LoRA for one epoch using the augmented dataset, and then use the model for inference.

---

## Training Prompt Example

```python
lis = []
for t in row["image_search_info_list"][:5]:
    lis.append(' '.join(t.split(' ')[:1000]))
info = "\n".join(lis)
messages = [
    {"role": "system", "content": "You are a helpful assistant that truthfully answers user questions about the provided image with informations that might be related to the question.\nKeep your response concise and to the point. If you don't know the answer, respond with 'I don't know'."},
    {"role": "user", "content": [{"type": "image"}]},
    {"role": "user", "content": f"informations that might be related to the question:{info}"},
    {"role": "user", "content": f"###user question:{row['query']}"},
]
```

---

## Data Augmentation Prompt Example

```python
prompt = f"""Given a question and a standard answer, please help me create 20 similar standard answers. You may either simplify or make the answers more complex, but each answer should not exceed 50 words. Output format:
1. xx (rule: concise|complex)
2. xx (rule: concise|complex)
3. xx
...
Question: {query}
Standard answer: {ans_full}
"""
```

---

## Results

- **Fine-tuning without RAG:** 0.01
- **Fine-tuning with RAG:** 0.02
- **Fine-tuning with RAG and data augmentation:** 0.044

---

## Pipeline Files

The pipeline consists of four main stages:

1. **Data Retrieval** (`0_recall.py`) — Generate search queries and retrieve relevant information.
2. **Data Synthesis** (`0_1_label_argument.py`) — Synthesize data by expanding labels to multiple labels.
3. **Create Training Data** (`1_create_train_data.py`) — Prepare data for model training.
4. **Model Training** (`src/run_note.sh`) — Fine-tune the model with LoRA.

---

This approach achieves significant improvements by leveraging retrieval-augmented generation and data augmentation, resulting in much better performance compared to simple fine-tuning.